{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ3u90dTbwNe"
      },
      "source": [
        "# **Objective:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYVeSvr4b8BJ"
      },
      "source": [
        "In this assignment, you will implement a Decision Tree Classifier from\n",
        "scratch using numpy. and apply it to the Adult Income Dataset. The\n",
        "task is to predict whether a person earns more than $50K per year. You will\n",
        "build the tree, evaluate it, and perform both pre-pruning and post-pruning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYF2Ch79cCJJ"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWgPbvkQcHPE"
      },
      "source": [
        "We will use the *Adult Income Dataset* from UCI.\n",
        "\n",
        "• Dataset link: Adult Dataset\n",
        "\n",
        "• Task: Binary classification (≤ 50K vs. > 50K).\n",
        "\n",
        "• Features: Mix of categorical (e.g., workclass, education, occupation)\n",
        "and numeric (e.g., age, hours-per-week).\n",
        "\n",
        "• Target: Income."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kmYuYtLccTu"
      },
      "source": [
        "# Loading Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KCQh1HHcglh"
      },
      "source": [
        "Use the following code to fetch the dataset:\n",
        "\n",
        "pip italicized text install ucimlrepo\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "adult = fetch_ucirepo(id=2)\n",
        "\n",
        "X = adult.data.features # features (pandas DataFrame)\n",
        "\n",
        "y = adult.data.targets # target (pandas DataFrame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2MTKUvogB4Q",
        "outputId": "0882e936-9ee4-457d-8d28-fce7acd7af8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmndF8ZBgOj9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier as SklearnDT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe9k-ysudIRd"
      },
      "source": [
        "# **Instructions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOCSt7pmdM4W"
      },
      "source": [
        "Follow these steps carefully. Do not skip any part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aULn8fHdPq3"
      },
      "source": [
        "**1. Data Preparation**\n",
        "\n",
        "• Handle missing values (drop or impute).\n",
        "\n",
        "• Encode categorical variables into numeric values (e.g., label encoding).\n",
        "\n",
        "• Split the dataset as:\n",
        "\n",
        "– 80% training\n",
        "\n",
        "– 20% validation\n",
        "\n",
        "– 20% test\n",
        "\n",
        "Use the validation set to tune depth and pruning."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'\n",
        "]\n",
        "\n",
        "data = pd.read_csv(url, names=columns, sep=',\\s*', engine='python', na_values='?')\n",
        "data = data.dropna()  # Remove rows with missing values\n",
        "\n",
        "# Features and target\n",
        "X = data.drop(columns=['income'])\n",
        "y = data['income']\n",
        "\n",
        "# Encode categorical features\n",
        "for col in X.select_dtypes('object').columns:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "y = LabelEncoder().fit_transform(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPsbeErOdG4u",
        "outputId": "05ab7fe1-4a2e-4716-cb99-7627612f72a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-332368444.py:8: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  data = pd.read_csv(url, names=columns, sep=',\\s*', engine='python', na_values='?')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)\n",
        "print('Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOh9sweggcpR",
        "outputId": "b9a46017-3bb6-491a-c6f6-7881173eb0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (18096, 14) Val: (6033, 14) Test: (6033, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqgirnlKdbbV"
      },
      "source": [
        "**2. Build a Decision Tree From Scratch**\n",
        "\n",
        "• Implement a tree recursively.\n",
        "\n",
        "• At each split:\n",
        "\n",
        "1. Compute both Gini Impurity and Entropy.\n",
        "\n",
        "2. For each feature and split, calculate the weighted impurity of child\n",
        "nodes.\n",
        "\n",
        "3. Choose the split with the highest information gain (lowest impu-\n",
        "rity).\n",
        "\n",
        "• Continue splitting until:\n",
        "\n",
        "– All samples in a node have the same label, OR\n",
        "\n",
        "– Maximum depth is reached, OR\n",
        "\n",
        "– No further improvement in impurity.\n",
        "\n",
        "• Implement a function to predict for new samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77a55f58-bfdf-4a19-8dbf-e1e616b77ba7"
      },
      "outputs": [],
      "source": [
        "# Decision Tree from Scratch\n",
        "class TreeNode:\n",
        "    def __init__(self, depth=0):\n",
        "        self.feature_idx = None\n",
        "        self.threshold = None\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.is_leaf = False\n",
        "        self.pred_label = None\n",
        "        self.depth = depth\n",
        "\n",
        "class DecisionTreeCustom:\n",
        "    def __init__(self, criterion='gini', max_depth=None, min_samples_split=2):\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = None\n",
        "\n",
        "    def _gini_index(self, y):\n",
        "        probs = np.bincount(y) / len(y)\n",
        "        return 1 - np.sum(probs ** 2)\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        probs = np.bincount(y) / len(y)\n",
        "        return -np.sum([p * np.log2(p) for p in probs if p > 0])\n",
        "\n",
        "    def _impurity(self, y):\n",
        "        return self._gini_index(y) if self.criterion == 'gini' else self._entropy(y)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_gain, best_feature, best_thresh = 0, None, None\n",
        "        parent_impurity = self._impurity(y)\n",
        "        for col in range(X.shape[1]):\n",
        "            unique_vals = np.unique(X[:, col])\n",
        "            if len(unique_vals) == 1:\n",
        "                continue\n",
        "            thresholds = (unique_vals[:-1] + unique_vals[1:]) / 2\n",
        "            for t in thresholds:\n",
        "                left_y = y[X[:, col] <= t]\n",
        "                right_y = y[X[:, col] > t]\n",
        "                if len(left_y) == 0 or len(right_y) == 0:\n",
        "                    continue\n",
        "                weighted_impurity = (len(left_y) * self._impurity(left_y) + len(right_y) * self._impurity(right_y)) / len(y)\n",
        "                gain = parent_impurity - weighted_impurity\n",
        "                if gain > best_gain:\n",
        "                    best_gain, best_feature, best_thresh = gain, col, t\n",
        "        return best_feature, best_thresh, best_gain\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        node = TreeNode(depth)\n",
        "        if len(np.unique(y)) == 1 or (self.max_depth and depth >= self.max_depth) or len(y) < self.min_samples_split:\n",
        "            node.is_leaf = True\n",
        "            node.pred_label = Counter(y).most_common(1)[0][0]\n",
        "            return node\n",
        "\n",
        "        feat, thr, gain = self._find_best_split(X, y)\n",
        "        if feat is None:\n",
        "            node.is_leaf = True\n",
        "            node.pred_label = Counter(y).most_common(1)[0][0]\n",
        "            return node\n",
        "\n",
        "        node.feature_idx = feat\n",
        "        node.threshold = thr\n",
        "        left_mask = X[:, feat] <= thr\n",
        "        right_mask = X[:, feat] > thr\n",
        "        node.left = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        node.right = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "        return node\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._build_tree(np.array(X), np.array(y), 0)\n",
        "\n",
        "    def _predict_sample(self, x, node):\n",
        "        if node.is_leaf:\n",
        "            return node.pred_label\n",
        "        if x[node.feature_idx] <= node.threshold:\n",
        "            return self._predict_sample(x, node.left)\n",
        "        else:\n",
        "            return self._predict_sample(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(x, self.root) for x in np.array(X)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2f9201wdng1"
      },
      "source": [
        "**3. Pre-Pruning (Restricting Tree Growth)**\n",
        "\n",
        "While building the tree:\n",
        "\n",
        "• Limit maximum depth (try depths = 2, 4, 6, and unlimited).\n",
        "\n",
        "• Require at least a minimum number of samples (e.g., 5) to split.\n",
        "\n",
        "• Require a minimum impurity decrease (optional)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Post-Pruning (Reduced Error Pruning)**\n",
        "\n",
        "1. First grow a full tree.\n",
        "\n",
        "2. Then, for each internal node:\n",
        "\n",
        "• Replace it with a leaf (majority class).\n",
        "\n",
        "• Check validation accuracy.\n",
        "\n",
        "3. If accuracy does not decrease, keep the pruning.\n",
        "\n",
        "4. Repeat until no further improvement."
      ],
      "metadata": {
        "id": "Uun7hUkEniHv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hltudCUqlBVW"
      },
      "outputs": [],
      "source": [
        "# Reduced Error Pruning\n",
        "def reduced_error_pruning(tree, X_val, y_val):\n",
        "    best_acc = accuracy_score(y_val, tree.predict(X_val))\n",
        "    improvement = True\n",
        "\n",
        "    def internal_nodes(node):\n",
        "        nodes_list = []\n",
        "        def traverse(n):\n",
        "            if n and not n.is_leaf:\n",
        "                nodes_list.append(n)\n",
        "                traverse(n.left)\n",
        "                traverse(n.right)\n",
        "        traverse(node)\n",
        "        return nodes_list\n",
        "\n",
        "    while improvement:\n",
        "        improvement = False\n",
        "        nodes = internal_nodes(tree.root)\n",
        "        for n in nodes:\n",
        "            backup = (n.feature_idx, n.threshold, n.left, n.right, n.is_leaf, n.pred_label)\n",
        "            n.is_leaf = True\n",
        "            n.left = n.right = None\n",
        "            n.pred_label = Counter(y_train).most_common(1)[0][0]\n",
        "            new_acc = accuracy_score(y_val, tree.predict(X_val))\n",
        "            if new_acc >= best_acc:\n",
        "                best_acc = new_acc\n",
        "                improvement = True\n",
        "            else:\n",
        "                n.feature_idx, n.threshold, n.left, n.right, n.is_leaf, n.pred_label = backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ec5283c-898f-404c-b68c-67b82e1b354f",
        "outputId": "d032f045-a6f6-492a-d367-671037b7d45e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8545534924845269\n",
            "Val Accuracy: 0.8506547323056523\n",
            "Validation accuracy before pruning: 0.8506547323056523\n",
            "Validation accuracy after pruning: 0.8511519973479198\n"
          ]
        }
      ],
      "source": [
        "# Train & Evaluate\n",
        "model_custom = DecisionTreeCustom(criterion='gini', max_depth=6, min_samples_split=5)\n",
        "model_custom.fit(X_train, y_train)\n",
        "\n",
        "print('Train Accuracy:', accuracy_score(y_train, model_custom.predict(X_train)))\n",
        "print('Val Accuracy:', accuracy_score(y_val, model_custom.predict(X_val)))\n",
        "\n",
        "print('Validation accuracy before pruning:', accuracy_score(y_val, model_custom.predict(X_val)))\n",
        "reduced_error_pruning(model_custom, X_val, y_val)\n",
        "print('Validation accuracy after pruning:', accuracy_score(y_val, model_custom.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2foYBAGSd38b"
      },
      "source": [
        "**5. Evaluation**\n",
        "\n",
        "• Train using the training set.\n",
        "\n",
        "• Tune depth and pruning using validation set.\n",
        "\n",
        "• Report final results on test set.\n",
        "\n",
        "• Metrics to report:\n",
        "\n",
        "– Accuracy\n",
        "\n",
        "– Precision, Recall, F1-score\n",
        "\n",
        "– Confusion Matrix\n",
        "\n",
        "• Compare your implementation with sklearn.tree.DecisionTreeClassifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt7AgpMUmBp7"
      },
      "outputs": [],
      "source": [
        "# Evaluating model\n",
        "def evaluate_model(model, X, y):\n",
        "    preds = model.predict(X)\n",
        "    print(\"Accuracy:\", accuracy_score(y, preds))\n",
        "    print(\"Precision:\", precision_score(y, preds, average='weighted'))\n",
        "    print(\"Recall:\", recall_score(y, preds, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y, preds, average='weighted'))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y, preds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing different depths\n",
        "for d in [2, 4, 6, None]:\n",
        "    print(f\"\\n Depth = {d}\")\n",
        "    m = DecisionTreeCustom(max_depth=d, min_samples_split=5)\n",
        "    m.fit(X_train, y_train)\n",
        "    evaluate_model(m, X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weKFUb7EnzXZ",
        "outputId": "547fcc05-4eb9-46b1-e748-f381937061a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Depth = 2\n",
            "Accuracy: 0.8219791148682247\n",
            "Precision: 0.8138132099089248\n",
            "Recall: 0.8219791148682247\n",
            "F1 Score: 0.8023114355673042\n",
            "Confusion Matrix:\n",
            " [[4332  199]\n",
            " [ 875  627]]\n",
            "\n",
            " Depth = 4\n",
            "Accuracy: 0.8478368970661363\n",
            "Precision: 0.8414250499153328\n",
            "Recall: 0.8478368970661363\n",
            "F1 Score: 0.8381950700834553\n",
            "Confusion Matrix:\n",
            " [[4294  237]\n",
            " [ 681  821]]\n",
            "\n",
            " Depth = 6\n",
            "Accuracy: 0.8506547323056523\n",
            "Precision: 0.8442326744157831\n",
            "Recall: 0.8506547323056523\n",
            "F1 Score: 0.8429707254503235\n",
            "Confusion Matrix:\n",
            " [[4268  263]\n",
            " [ 638  864]]\n",
            "\n",
            " Depth = None\n",
            "Accuracy: 0.8092159787833582\n",
            "Precision: 0.8114496068372945\n",
            "Recall: 0.8092159787833582\n",
            "F1 Score: 0.810268552844933\n",
            "Confusion Matrix:\n",
            " [[3930  601]\n",
            " [ 550  952]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU3xIk4GeIYU"
      },
      "source": [
        "**6. Experiments to Perform**\n",
        "\n",
        "• Compare Gini vs. Entropy.\n",
        "\n",
        "• Compare different depths (2, 4, 6, unlimited).\n",
        "\n",
        "• Show effect of pruning (pre-pruned vs. post-pruned vs. full tree).\n",
        "\n",
        "• Identify the most important features (which features are used at the\n",
        "top of the tree)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare criteria\n",
        "for c in ['gini', 'entropy']:\n",
        "    print(f\"\\n Criterion = {c} \")\n",
        "    m = DecisionTreeCustom(criterion=c, max_depth=6)\n",
        "    m.fit(X_train, y_train)\n",
        "    evaluate_model(m, X_val, y_val)"
      ],
      "metadata": {
        "id": "gx89YZp49E_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d24e2d-a055-4b71-fd56-8e4a1db6ec37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Criterion = gini \n",
            "Accuracy: 0.8508204873197415\n",
            "Precision: 0.8444173850022059\n",
            "Recall: 0.8508204873197415\n",
            "F1 Score: 0.8431698246308788\n",
            "Confusion Matrix:\n",
            " [[4268  263]\n",
            " [ 637  865]]\n",
            "\n",
            " Criterion = entropy \n",
            "Accuracy: 0.8508204873197415\n",
            "Precision: 0.8452931458381515\n",
            "Recall: 0.8508204873197415\n",
            "F1 Score: 0.840608636904044\n",
            "Confusion Matrix:\n",
            " [[4317  214]\n",
            " [ 686  816]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sklearn comparison\n",
        "sk_model = SklearnDT(criterion='gini', max_depth=6, random_state=42)\n",
        "sk_model.fit(X_train, y_train)\n",
        "print('Sklearn Test Accuracy:', accuracy_score(y_test, sk_model.predict(X_test)))\n",
        "print('Scratch Test Accuracy:', accuracy_score(y_test, model_custom.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF2T4gBIoAie",
        "outputId": "300afa9b-2aa7-4ef0-c6b4-09e44f2b7748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Test Accuracy: 0.8470081219956904\n",
            "Scratch Test Accuracy: 0.8468423669816012\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}